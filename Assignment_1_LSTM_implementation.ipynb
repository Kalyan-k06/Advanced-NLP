{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OBw__kO4P8-h"
   },
   "outputs": [],
   "source": [
    "# For tips on running notebooks in Google Colab, see\n",
    "# https://pytorch.org/tutorials/beginner/colab\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KbGaKcUP8-j"
   },
   "source": [
    "LSTMs in Pytorch\n",
    "----------------\n",
    "\n",
    "Before getting to the example, note a few things. Pytorch\\'s LSTM\n",
    "expects all of its inputs to be 3D tensors. The semantics of the axes of\n",
    "these tensors is important. The first axis is the sequence itself, the\n",
    "second indexes instances in the mini-batch, and the third indexes\n",
    "elements of the input. We haven\\'t discussed mini-batching, so let\\'s\n",
    "just ignore that and assume we will always have just 1 dimension on the\n",
    "second axis. If we want to run the sequence model over the sentence\n",
    "\\\"The cow jumped\\\", our input should look like\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\begin{bmatrix}\n",
    "\\overbrace{q_\\text{The}}^\\text{row vector} \\\\\n",
    "q_\\text{cow} \\\\\n",
    "q_\\text{jumped}\n",
    "\\end{bmatrix}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Except remember there is an additional 2nd dimension with size 1.\n",
    "\n",
    "In addition, you could go through the sequence one at a time, in which\n",
    "case the 1st axis will have size 1 also.\n",
    "\n",
    "Let\\'s see a quick example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5c1NjwFwP8-k",
    "outputId": "5c52e6bb-54a4-4e5e-f937-34638e75b191"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11378f470>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmildQ69P8-l",
    "outputId": "de33b125-4bc4-4741-a652-bf579171ace8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
      "\n",
      "        [[-0.3521,  0.1026, -0.2971]],\n",
      "\n",
      "        [[-0.3191,  0.0781, -0.1957]],\n",
      "\n",
      "        [[-0.1634,  0.0941, -0.1637]],\n",
      "\n",
      "        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>)\n",
      "(tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>), tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_AUa14R0RDXY",
    "outputId": "7ef5969c-1e9c-4f25-9dcc-94b6ff708159"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review sentiment\n",
       "0           0  One of the other reviewers has mentioned that ...  positive\n",
       "1           1  A wonderful little production. <br /><br />The...  positive\n",
       "2           2  I thought this was a wonderful way to spend ti...  positive\n",
       "3           4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "4           5  Probably my all-time favorite movie, a story o...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#make sure to upload 'imdb_small.csv' to the local directory\n",
    "imdb_dataset = pd.read_csv(\"imdb_small.csv\")\n",
    "#take a look at the data\n",
    "imdb_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "q-MKUrmb4qDd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>First of all, let's get a few things straight ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>This a fantastic movie of three prisoners who ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>This was the worst movie I saw at WorldFest an...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>After the success of Die Hard and it's sequels...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>I watched this film not really expecting much,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27</td>\n",
       "      <td>This film tried to be too many things all at o...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19</td>\n",
       "      <td>An awful film! It must have been up against so...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29</td>\n",
       "      <td>'War movie' is a Hollywood genre that has been...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>The Karen Carpenter Story shows a little more ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>I saw this movie when I was about 12 when it c...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>28</td>\n",
       "      <td>This movie was so frustrating. Everything seem...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>I remember this film,it was the first film i h...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>21</td>\n",
       "      <td>I had the terrible misfortune of having to vie...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>26</td>\n",
       "      <td>\"The Cell\" is an exotic masterpiece, a dizzyin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>41</td>\n",
       "      <td>This movie is based on the book, \"A Many Splen...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30</td>\n",
       "      <td>Taut and organically gripping, Edward Dmytryk'...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>15</td>\n",
       "      <td>Kind of drawn in by the erotic scenes, only to...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>What an absolutely stunning movie, if you have...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>Phil the Alien is one of those quirky films wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>So im not a big fan of Boll's work but then ag...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9</td>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>31</td>\n",
       "      <td>\"Ardh Satya\" is one of the finest film ever ma...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>16</td>\n",
       "      <td>Some films just simply should not be remade. T...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>8</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13</td>\n",
       "      <td>The cast played Shakespeare.&lt;br /&gt;&lt;br /&gt;Shakes...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>My first exposure to the Templarios &amp; not a go...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>37</td>\n",
       "      <td>Ever watched a movie that lost the plot? Well,...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>I bought this film at Blockbuster for $3.00, b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>The plot is about the death of little children...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>Okay, so this series kind of takes the route o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>33</td>\n",
       "      <td>One of the most significant quotes from the en...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>17</td>\n",
       "      <td>This movie made it into one of my top 10 most ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                             review sentiment\n",
       "0           23  First of all, let's get a few things straight ...  negative\n",
       "1            3  Basically there's a family where a little boy ...  negative\n",
       "2           14  This a fantastic movie of three prisoners who ...  positive\n",
       "3           24  This was the worst movie I saw at WorldFest an...  negative\n",
       "4           20  After the success of Die Hard and it's sequels...  positive\n",
       "5           34  I watched this film not really expecting much,...  negative\n",
       "6           27  This film tried to be too many things all at o...  negative\n",
       "7           19  An awful film! It must have been up against so...  negative\n",
       "8           29  'War movie' is a Hollywood genre that has been...  positive\n",
       "9           25  The Karen Carpenter Story shows a little more ...  positive\n",
       "10          11  I saw this movie when I was about 12 when it c...  negative\n",
       "11           0  One of the other reviewers has mentioned that ...  positive\n",
       "12           1  A wonderful little production. <br /><br />The...  positive\n",
       "13          28  This movie was so frustrating. Everything seem...  negative\n",
       "14          18  I remember this film,it was the first film i h...  positive\n",
       "15          21  I had the terrible misfortune of having to vie...  negative\n",
       "16           4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "17          26  \"The Cell\" is an exotic masterpiece, a dizzyin...  positive\n",
       "18          41  This movie is based on the book, \"A Many Splen...  positive\n",
       "19          30  Taut and organically gripping, Edward Dmytryk'...  positive\n",
       "20           5  Probably my all-time favorite movie, a story o...  positive\n",
       "21          15  Kind of drawn in by the erotic scenes, only to...  negative\n",
       "22           6  I sure would like to see a resurrection of a u...  positive\n",
       "23          22  What an absolutely stunning movie, if you have...  positive\n",
       "24          10  Phil the Alien is one of those quirky films wh...  negative\n",
       "25          12  So im not a big fan of Boll's work but then ag...  negative\n",
       "26           7  This show was an amazing, fresh & innovative i...  negative\n",
       "27           9  If you like original gut wrenching laughter yo...  positive\n",
       "28          31  \"Ardh Satya\" is one of the finest film ever ma...  positive\n",
       "29          16  Some films just simply should not be remade. T...  positive\n",
       "30           2  I thought this was a wonderful way to spend ti...  positive\n",
       "31           8  Encouraged by the positive comments about this...  negative\n",
       "32          13  The cast played Shakespeare.<br /><br />Shakes...  negative\n",
       "33          32  My first exposure to the Templarios & not a go...  negative\n",
       "34          37  Ever watched a movie that lost the plot? Well,...  negative\n",
       "35          35  I bought this film at Blockbuster for $3.00, b...  negative\n",
       "36          36  The plot is about the death of little children...  negative\n",
       "37          38  Okay, so this series kind of takes the route o...  positive\n",
       "38          33  One of the most significant quotes from the en...  positive\n",
       "39          17  This movie made it into one of my top 10 most ...  negative"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Most students don't have access to GPUs so create a tiny version of the dataset that can fit on a CPU\n",
    "imdb_dataset = pd.concat([imdb_dataset[imdb_dataset.sentiment=='positive'].head(n=20),\n",
    "                          imdb_dataset[imdb_dataset.sentiment=='negative'].head(n=20)])\n",
    "imdb_dataset = imdb_dataset.sample(frac=1).reset_index(drop=True)\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YlQlhDKbjKix"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tlv9lXOvRbmy"
   },
   "source": [
    "### Preprocessing\n",
    " Remove Punctuation and get all the words from review dataset. Count all the words and sort it based on counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pei6OajTjQTy",
    "outputId": "95a311f2-3e37-4c21-bd57-208f487f4bdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This is a positive sentence.', 'This is a negative sentence.')\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "texts = [\"This is a positive sentence.\", \"This is a negative sentence.\"]\n",
    "labels = [1, 0]\n",
    "\n",
    "dataset = TextDataset(texts, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=2)\n",
    "\n",
    "for batch in dataloader:\n",
    "    texts_batch, labels_batch = batch\n",
    "    print(texts_batch)\n",
    "    print(labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Ev-QYIORByG",
    "outputId": "d11747c9-f5b4-49a8-a2c6-8860388d03a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten occuring words : [('the', 541), ('a', 260), ('of', 253), ('to', 200), ('and', 197), ('is', 164), ('in', 132), ('br', 114), ('i', 108), ('it', 106)]\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from collections import Counter\n",
    "all_reviews=list()\n",
    "for text in imdb_dataset.review.to_list():\n",
    "  text = text.lower()\n",
    "  text = \"\".join([ch for ch in text if ch not in punctuation])\n",
    "  all_reviews.append(text)\n",
    "all_text = \" \".join(all_reviews)\n",
    "all_words = all_text.split()\n",
    "\n",
    "# Count all the words using Counter Method\n",
    "count_words = Counter(all_words)\n",
    "total_words=len(all_words)\n",
    "sorted_words=count_words.most_common(total_words)\n",
    "print(f\"Top ten occuring words : {sorted_words[:10]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PM2wDxESAwv"
   },
   "source": [
    "### Tokenization\n",
    " Create a dictionary to convert words to Integers based on the number of occurrence of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yMcFeNbtR_9M",
    "outputId": "9355e130-b3ff-4ab2-b48c-7c3fc488b6c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'a': 2, 'of': 3, 'to': 4, 'and': 5, 'is': 6, 'in': 7, 'br': 8, 'i': 9, 'it': 10, 'this': 11, 'that': 12, 'was': 13, 'movie': 14, 'but': 15, 'with': 16, 'as': 17, 'for': 18, 'film': 19, 'not': 20, 'on': 21, 'its': 22, 'one': 23, 'you': 24, 'all': 25, 'at': 26, 'are': 27, 'by': 28, 'be': 29, 'have': 30, 'his': 31, 'so': 32, 'like': 33, 'from': 34, 'or': 35, 'just': 36, 'an': 37, 'what': 38, 'if': 39, 'who': 40, 'even': 41, 'some': 42, 'about': 43, 'out': 44, 'only': 45, 'he': 46, 'no': 47, 'has': 48, 'when': 49, 'my': 50, 'more': 51, 'they': 52, 'first': 53, 'very': 54, 'me': 55, 'see': 56, 'there': 57, 'we': 58, 'story': 59, 'been': 60, 'than': 61, 'much': 62, 'up': 63, 'would': 64, 'time': 65, 'which': 66, 'most': 67, 'into': 68, 'because': 69, 'bad': 70, 'way': 71, 'will': 72, 'good': 73, 'never': 74, 'go': 75, 'how': 76, 'far': 77, 'war': 78, 'show': 79, 'then': 80, 'little': 81, 'say': 82, 'do': 83, 'scenes': 84, 'another': 85, 'where': 86, 'them': 87, 'least': 88, 'really': 89, 'love': 90, 'were': 91, 'people': 92, 'movies': 93, 'too': 94, 'pretty': 95, 'films': 96, 'their': 97, 'ive': 98, 'end': 99, 'other': 100, 'thing': 101, 'three': 102, 'life': 103, 'acting': 104, 'does': 105, 'many': 106, 'best': 107, 'her': 108, 'could': 109, 'any': 110, 'though': 111, 'young': 112, 'few': 113, 'watch': 114, 'your': 115, 'down': 116, 'find': 117, 'man': 118, 'also': 119, 'such': 120, 'great': 121, 'better': 122, 'character': 123, 'cant': 124, 'those': 125, 'however': 126, 'may': 127, 'right': 128, 'made': 129, 'these': 130, 'characters': 131, 'police': 132, 'him': 133, 'get': 134, 'comes': 135, 'going': 136, 'same': 137, 'well': 138, 'can': 139, 'hard': 140, 'back': 141, 'mountain': 142, 'got': 143, 'dont': 144, 'beautiful': 145, 'while': 146, 'truly': 147, 'played': 148, 'still': 149, 'us': 150, 'terrible': 151, 'im': 152, 'make': 153, 'must': 154, 'actors': 155, 'big': 156, 'actually': 157, 'killer': 158, 'bit': 159, 'interesting': 160, 'thats': 161, 'had': 162, 'thought': 163, 'seen': 164, 'watching': 165, 'true': 166, 'director': 167, 'itself': 168, 'something': 169, 'scene': 170, 'violence': 171, 'cinema': 172, 'world': 173, 'through': 174, 'goes': 175, 'again': 176, 'fun': 177, 'theres': 178, 'real': 179, 'watched': 180, 'saw': 181, 'work': 182, 'original': 183, 'after': 184, 'especially': 185, 'serial': 186, 'own': 187, 'know': 188, 'lot': 189, 'off': 190, 'rather': 191, 'simply': 192, 'times': 193, 'plot': 194, 'cold': 195, 'around': 196, 'home': 197, 'use': 198, 'someone': 199, 'top': 200, 'point': 201, 'gets': 202, 'cast': 203, 'titta': 204, 'things': 205, 'here': 206, 'seems': 207, 'bmovie': 208, 'look': 209, 'action': 210, 'enjoy': 211, 'rest': 212, 'ridiculous': 213, 'wrong': 214, 'did': 215, 'full': 216, 'forget': 217, 'girl': 218, 'human': 219, 'under': 220, 'nice': 221, 'whole': 222, 'nothing': 223, 'funny': 224, 'hollywood': 225, 'enough': 226, 'taken': 227, 'awful': 228, 'against': 229, 'gives': 230, 'audience': 231, 'she': 232, 'beginning': 233, 'old': 234, 'now': 235, 'since': 236, 'oz': 237, 'ever': 238, 'being': 239, 'let': 240, 'having': 241, 'money': 242, 'mr': 243, 'cell': 244, 'mind': 245, 'makes': 246, 'before': 247, 'murder': 248, 'years': 249, 'series': 250, 'boll': 251, 'carver': 252, 'di': 253, 'always': 254, 'fact': 255, 'worse': 256, 'over': 257, 'give': 258, 'boring': 259, 'become': 260, 'family': 261, 'jake': 262, 'parents': 263, 'drama': 264, 'worst': 265, 'think': 266, 'based': 267, 'success': 268, 'place': 269, 'every': 270, 'band': 271, 'performance': 272, 'hes': 273, 'half': 274, 'star': 275, 'wasnt': 276, 'romantic': 277, 'comedy': 278, 'lack': 279, 'writing': 280, 'direction': 281, 'beyond': 282, 'fine': 283, 'why': 284, 'version': 285, 'inman': 286, 'ada': 287, 'takes': 288, 'wonderful': 289, 'between': 290, 'sure': 291, 'karen': 292, 'role': 293, 'air': 294, 'exactly': 295, 'set': 296, 'death': 297, 'our': 298, 'everything': 299, 'weird': 300, 'person': 301, 'almost': 302, 'towards': 303, 'different': 304, 'new': 305, 'tell': 306, 'heard': 307, 'looks': 308, 'kind': 309, 'during': 310, 'ryan': 311, 'wanna': 312, 'apparently': 313, 'cry': 314, 'mumbai': 315, 'anand': 316, 'house': 317, 'halfway': 318, 'le': 319, 'conseguenze': 320, 'dellamore': 321, 'lets': 322, 'fan': 323, 'matter': 324, 'several': 325, 'crappy': 326, 'cheap': 327, 'remember': 328, 'kids': 329, 'live': 330, 'dialogue': 331, 'take': 332, 'honestly': 333, 'timebr': 334, 'painful': 335, 'giving': 336, 'itbr': 337, 'both': 338, 'kill': 339, 'thriller': 340, 'totally': 341, 'similar': 342, 'instead': 343, '10': 344, 'playing': 345, 'fantastic': 346, 'soundtrack': 347, 'constant': 348, 'amount': 349, 'minutes': 350, 'actress': 351, 'part': 352, 'main': 353, 'unsympathetic': 354, 'emotional': 355, 'actor': 356, 'feel': 357, 'die': 358, 'dream': 359, 'portrait': 360, 'michael': 361, 'hal': 362, 'mention': 363, 'yes': 364, 'looking': 365, 'view': 366, 'lead': 367, 'looked': 368, 'worth': 369, 'reason': 370, 'quite': 371, 'once': 372, 'blockbuster': 373, 'turning': 374, 'behind': 375, 'production': 376, 'cause': 377, 'nominated': 378, 'bizarre': 379, 'script': 380, 'done': 381, 'sequences': 382, 'brings': 383, 'screen': 384, 'becomes': 385, 'southern': 386, 'left': 387, 'indeed': 388, 'earlier': 389, 'scenario': 390, 'long': 391, 'coming': 392, 'perhaps': 393, 'two': 394, 'unfolds': 395, 'surprisingly': 396, 'performances': 397, 'dark': 398, 'onto': 399, 'carpenter': 400, 'fails': 401, 'sort': 402, 'kid': 403, 'monster': 404, 'didnt': 405, 'year': 406, 'took': 407, 'making': 408, 'classic': 409, 'called': 410, 'given': 411, 'city': 412, 'prison': 413, 'high': 414, 'due': 415, 'wouldnt': 416, 'nasty': 417, 'away': 418, 'turned': 419, 'piece': 420, 'need': 421, 'final': 422, 'horrible': 423, '20': 424, 'miles': 425, 'try': 426, 'relations': 427, 'play': 428, 'theme': 429, 'imagination': 430, 'trying': 431, 'walk': 432, 'robert': 433, 'major': 434, 'change': 435, 'children': 436, 'slow': 437, 'today': 438, 'bring': 439, 'tv': 440, 'believe': 441, 'eventually': 442, 'lost': 443, 'cannot': 444, 'idea': 445, '70s': 446, 'waste': 447, '2': 448, 'system': 449, 'approach': 450, 'shakespeare': 451, 'ten': 452, 'video': 453, 'spider': 454, 'victim': 455, 'suicide': 456, 'david': 457, 'italy': 458, 'hotel': 459, 'girolamos': 460, 'bluff': 461, 'consequences': 462, 'machine': 463, 'am': 464, 'anime': 465, 'speed': 466, 'racer': 467, 'b': 468, 'bmovies': 469, 'hilarious': 470, 'godzilla': 471, 'usual': 472, 'fx': 473, 'animation': 474, 'run': 475, 'school': 476, 'english': 477, 'dad': 478, 'dvd': 479, 'jokes': 480, 'comments': 481, 'season': 482, 'barely': 483, 'unintentionally': 484, '310': 485, 'originally': 486, 'counting': 487, 'unless': 488, '15': 489, 'closet': 490, 'fighting': 491, 'decides': 492, 'youre': 493, 'decide': 494, 'shots': 495, 'famous': 496, 'george': 497, 'everybody': 498, 'recognition': 499, 'shes': 500, 'predictable': 501, 'doesnt': 502, 'nor': 503, 'development': 504, 'cop': 505, '90s': 506, 'guy': 507, 'cliffhanger': 508, 'rescue': 509, 'mom': 510, 'shoot': 511, 'skills': 512, 'managed': 513, 'entertaining': 514, 'delivers': 515, 'plenty': 516, 'john': 517, 'tick': 518, 'constantly': 519, 'anybody': 520, 'whilst': 521, 'using': 522, 'help': 523, 'needed': 524, 'cares': 525, 'expectations': 526, 'turn': 527, 'wearing': 528, 'stretching': 529, 'points': 530, 'touch': 531, 'drummer': 532, 'annoying': 533, 'problem': 534, 'attempt': 535, 'happens': 536, 'utterly': 537, 'tedious': 538, 'forward': 539, 'ready': 540, 'singer': 541, 'hell': 542, 'havent': 543, 'mentioned': 544, 'london': 545, 'exception': 546, 'certainly': 547, 'tried': 548, 'political': 549, 'failed': 550, 'interest': 551, 'keep': 552, 'until': 553, 'although': 554, 'appreciate': 555, 'spirit': 556, 'effort': 557, 'existence': 558, 'critique': 559, 'poor': 560, 'filmbr': 561, 'happening': 562, 'reminds': 563, 'kings': 564, 'genuine': 565, 'concern': 566, 'theyve': 567, 'renaissance': 568, 'facts': 569, 'come': 570, 'werent': 571, 'hours': 572, 'theyd': 573, 'genre': 574, 'along': 575, 'compelling': 576, 'silver': 577, 'civil': 578, 'starring': 579, 'jude': 580, 'law': 581, 'nicole': 582, 'kidman': 583, 'renée': 584, 'zellweger': 585, 'entirely': 586, 'accurate': 587, 'battle': 588, 'sequence': 589, 'edward': 590, 'shame': 591, 'soldier': 592, 'gruesome': 593, 'north': 594, 'carolina': 595, 'appears': 596, 'root': 597, 'soldiers': 598, 'soon': 599, 'hero': 600, 'incidentally': 601, 'wanting': 602, 'meanwhile': 603, 'farm': 604, 'adas': 605, 'course': 606, 'helps': 607, 'together': 608, 'cope': 609, 'loneliness': 610, 'brought': 611, 'upon': 612, 'within': 613, 'settings': 614, 'vivid': 615, 'whom': 616, 'complex': 617, 'father': 618, 'ray': 619, 'deeply': 620, 'mother': 621, 'affected': 622, 'changed': 623, 'mostly': 624, 'message': 625, 'land': 626, 'past': 627, 'century': 628, 'atmosphere': 629, 'unfortunately': 630, 'absurd': 631, 'nature': 632, 'relationship': 633, 'mistake': 634, 'romance': 635, 'unique': 636, 'torn': 637, 'altogether': 638, 'shows': 639, 'plays': 640, 'stronger': 641, 'job': 642, 'included': 643, '12': 644, 'came': 645, 'recall': 646, 'eating': 647, 'men': 648, 'formula': 649, 'usually': 650, 'daughter': 651, 'happy': 652, 'died': 653, 'episode': 654, 'struck': 655, 'drugs': 656, 'sex': 657, 'face': 658, 'agenda': 659, 'irish': 660, 'appeal': 661, 'dare': 662, 'wholl': 663, 'inmates': 664, 'experience': 665, 'sense': 666, 'realism': 667, 'entire': 668, 'editing': 669, 'particularly': 670, 'seemed': 671, 'id': 672, 'stand': 673, 'hated': 674, 'stereotypical': 675, 'talk': 676, 'hanging': 677, 'picture': 678, 'brother': 679, 'newbury': 680, 'tigers': 681, 'lots': 682, 'anyone': 683, 'knows': 684, 'others': 685, 'save': 686, 'aspects': 687, 'believable': 688, 'supposed': 689, 'sexy': 690, 'costumes': 691, 'matteis': 692, 'stunning': 693, 'mattei': 694, 'offers': 695, 'each': 696, 'next': 697, 'sincere': 698, 'steve': 699, 'talented': 700, 'read': 701, 'style': 702, 'door': 703, 'tarsem': 704, 'want': 705, 'inside': 706, 'physically': 707, 'less': 708, 'jennifer': 709, 'brain': 710, 'guess': 711, 'ventures': 712, 'inbr': 713, 'noticed': 714, 'maybe': 715, 'contrast': 716, 'cinematography': 717, 'else': 718, 'theater': 719, 'china': 720, 'hong': 721, 'kong': 722, 'memorable': 723, 'song': 724, 'lovers': 725, 'moments': 726, 'spend': 727, 'crossfire': 728, 'bars': 729, 'drunk': 730, 'mitchum': 731, 'whos': 732, 'ryans': 733, 'second': 734, 'third': 735, 'dmytryk': 736, 'white': 737, 'paul': 738, 'small': 739, 'dealt': 740, 'news': 741, 'felt': 742, 'antisemitism': 743, 'fit': 744, 'odd': 745, 'discreet': 746, 'probably': 747, 'favorite': 748, 'last': 749, '25': 750, 'eyes': 751, 'sympathetic': 752, 'roles': 753, 'says': 754, 'whats': 755, 'realize': 756, 'unbelievable': 757, 'town': 758, 'brilliant': 759, 'seahunt': 760, 'black': 761, 'sea': 762, 'pace': 763, 'lines': 764, 'absolutely': 765, 'wont': 766, 'liked': 767, 'music': 768, 'start': 769, 'oddness': 770, 'bolls': 771, 'enjoyed': 772, 'bought': 773, 'research': 774, 'island': 775, 'should': 776, 'warned': 777, 'feeling': 778, 'names': 779, 'til': 780, 'schweiger': 781, 'udo': 782, 'kier': 783, 'storyline': 784, 'gms': 785, 'disappointed': 786, 'innovative': 787, 'decline': 788, 'followed': 789, 'ardh': 790, 'satya': 791, 'govind': 792, 'nihalani': 793, 'leading': 794, 'tells': 795, 'unlike': 796, 'practical': 797, 'velankar': 798, 'fathers': 799, 'anands': 800, 'crime': 801, 'frustrations': 802, 'finally': 803, 'terror': 804, 'title': 805, 'excellent': 806, 'sitting': 807, 'lame': 808, 'keitel': 809, 'scottish': 810, 'write': 811, 'ultimately': 812, 'begin': 813, 'created': 814, 'yet': 815, 'except': 816, 'provide': 817, 'killings': 818, 'irrelevant': 819, 'struggle': 820, 'miniskirt': 821, 'restricted': 822, 'sticker': 823, 'age': 824, 'panties': 825, 'pg13': 826, 'rated': 827, 'rent': 828, 'edited': 829, 'suicides': 830, 'teenagers': 831, 'chance': 832, 'hopper': 833, 'troubles': 834, 'caught': 835, 'week': 836, 'girolamo': 837, 'introduced': 838, 'nonlife': 839, 'bank': 840, 'spectators': 841, 'without': 842, 'appearing': 843, 'truth': 844, 'spectator': 845, 'reveal': 846, 'unexpectedly': 847, 'limbalsamatore': 848, 'insomnia': 849, 'fight': 850, 'stolen': 851, 'wars': 852, 'nazis': 853, 'juvenile': 854, 'straight': 855, 'used': 856, 'preschool': 857, 'theyre': 858, 'c': 859, 'lotbr': 860, 'moving': 861, 'sudden': 862, 'boom': 863, 'wwwaaaaayyyyy': 864, 'downhillbr': 865, 'crissakes': 866, 'vividly': 867, 'bunch': 868, 'dinosaurs': 869, 'addition': 870, 'transition': 871, 'unorganized': 872, 'voicesespecially': 873, 'dub': 874, 'viewed': 875, 'horrid': 876, 'begging': 877, 'tape': 878, 'vhs': 879, 'player': 880, 'kept': 881, 'surviving': 882, 'cracking': 883, 'robots': 884, 'joelmike': 885, 'mst3k': 886, 'pick': 887, 'survive': 888, 'heck': 889, 'planning': 890, 'fellow': 891, 'otaku': 892, 'pal': 893, 'mine': 894, 'halloween': 895, 'night': 896, 'stupid': 897, 'improvement': 898, '0510': 899, 'according': 900, 'grading': 901, 'scale': 902, 'means': 903, 'basically': 904, 'boy': 905, 'thinks': 906, 'zombie': 907, 'slower': 908, 'soap': 909, 'opera': 910, 'suddenly': 911, 'rambo': 912, 'zombiebr': 913, 'ok': 914, 'watchable': 915, 'divorcing': 916, 'arguing': 917, 'ruins': 918, 'expected': 919, 'boogeyman': 920, 'meaningless': 921, 'spotsbr': 922, '3': 923, 'descent': 924, 'dialogs': 925, 'ignore': 926, 'prisoners': 927, 'clooney': 928, 'roll': 929, 'sorrow': 930, 'recommand': 931, 'greetings': 932, 'bart': 933, 'worldfest': 934, 'received': 935, 'applause': 936, 'afterwards': 937, 'receiving': 938, 'known': 939, 'jbeals': 940, 'mparker': 941, 'allowed': 942, 'judge': 943, 'therefore': 944, 'bore': 945, 'depth': 946, 'revolving': 947, 'feels': 948, 'straighttovideo': 949, 'standardsbr': 950, 'sequels': 951, 'surprise': 952, '1990s': 953, 'glut': 954, 'cashed': 955, 'concept': 956, 'sly': 957, 'stop': 958, 'stallones': 959, 'careerbr': 960, 'nitpickers': 961, 'expert': 962, 'climbing': 963, 'basejumping': 964, 'aviation': 965, 'facial': 966, 'expressions': 967, 'excuses': 968, 'dismiss': 969, 'overblown': 970, 'pile': 971, 'junk': 972, 'stallone': 973, 'outacted': 974, 'horse': 975, 'nonsense': 976, 'lovable': 977, 'undeniably': 978, 'romp': 979, 'thrills': 980, 'laughsbr': 981, 'youve': 982, 'lithgows': 983, 'sneery': 984, 'evilness': 985, 'box': 986, 'baddies': 987, 'permanently': 988, 'harassed': 989, 'hapless': 990, 'turncoat': 991, 'agent': 992, 'rex': 993, 'linn': 994, 'traversbr': 995, 'henry': 996, 'rooker': 997, 'noteworthy': 998, 'cringeworthy': 999, 'insists': 1000, 'shrieking': 1001, 'disbelief': 1002, 'captors': 1003, 'hurt': 1004, 'surely': 1005, 'ralph': 1006, 'waites': 1007, 'frank': 1008, 'grinning': 1009, 'plummets': 1010, 'deathbr': 1011, 'former': 1012, 'londons': 1013, 'burning': 1014, 'craig': 1015, 'fairbrass': 1016, 'brit': 1017, 'cropper': 1018, 'football': 1019, 'kickingbr': 1020, 'judgement': 1021, 'happen': 1022, 'lower': 1023, 'volume': 1024, 'qaulen': 1025, 'helicopter': 1026, 'expecting': 1027, 'pack': 1028, '5': 1029, 'fiver': 1030, 'expect': 1031, 'occasional': 1032, 'camcorder': 1033, 'ie': 1034, 'damned': 1035, 'assume': 1036, 'build': 1037, 'tension': 1038, 'thumb': 1039, 'fast': 1040, 'button': 1041, 'press': 1042, 'gave': 1043, 'seriously': 1044, 'coz': 1045, 'meercat': 1046, 'gonna': 1047, 'explaining': 1048, 'anyway': 1049, 'concerned': 1050, 'talent': 1051, 'avoid': 1052, 'bored': 1053, 'paint': 1054, 'dry': 1055, 'stinging': 1056, 'satire': 1057, 'sappy': 1058, 'values': 1059, 'promo': 1060, 'list': 1061, 'miserably': 1062, 'endbr': 1063, 'inc': 1064, 'depresses': 1065, 'clumsy': 1066, 'targets': 1067, 'reflect': 1068, 'serious': 1069, 'particular': 1070, 'corporatization': 1071, 'poking': 1072, 'diminishes': 1073, 'atrocity': 1074, 'similarly': 1075, 'trivializes': 1076, 'stinkers': 1077, 'golden': 1078, 'globe': 1079, 'female': 1080, 'painter': 1081, 'mangled': 1082, 'complaint': 1083, 'liberties': 1084, 'perfectly': 1085, 'accounts': 1086, 'artist': 1087, 'dishwaterdull': 1088, 'suppose': 1089, 'naked': 1090, 'factual': 1091, 'hurriedly': 1092, 'capped': 1093, 'summary': 1094, 'artists': 1095, 'saved': 1096, 'ourselves': 1097, 'couple': 1098, 'favored': 1099, 'brevity': 1100, 'redone': 1101, 'clichéd': 1102, 'rehashed': 1103, 'overthetop': 1104, 'seem': 1105, 'unavoidable': 1106, 'conflict': 1107, 'dealing': 1108, 'largescale': 1109, 'combat': 1110, 'grain': 1111, 'warera': 1112, 'calling': 1113, 'opens': 1114, 'literally': 1115, 'quickanddirty': 1116, 'puts': 1117, 'glory': 1118, 'zwick': 1119, 'period': 1120, 'centers': 1121, 'disgruntled': 1122, 'confederate': 1123, 'disgusted': 1124, 'homesick': 1125, 'hamlet': 1126, 'equally': 1127, 'belle': 1128, 'monroe': 1129, 'glance': 1130, 'setup': 1131, 'formulaic': 1132, 'sympathy': 1133, 'reluctant': 1134, 'tribulations': 1135, 'battlefield': 1136, 'segments': 1137, 'relatively': 1138, 'unimpressive': 1139, 'somewhat': 1140, 'contrivedbr': 1141, 'drastic': 1142, 'intrepid': 1143, 'turns': 1144, 'deserter': 1145, 'saving': 1146, 'potentially': 1147, 'confusing': 1148, 'confederates': 1149, 'begins': 1150, 'odyssey': 1151, 'homeward': 1152, 'cultured': 1153, 'ways': 1154, 'prove': 1155, 'fields': 1156, 'transformed': 1157, 'wilderbeast': 1158, 'toughasnails': 1159, 'ruby': 1160, 'thewes': 1161, 'put': 1162, 'importantly': 1163, 'isolation': 1164, 'adabr': 1165, 'disturbing': 1166, 'wartorn': 1167, 'south': 1168, 'interact': 1169, 'enhanced': 1170, 'brendan': 1171, 'gleeson': 1172, 'rubys': 1173, 'deadbeat': 1174, 'winstone': 1175, 'unrepentant': 1176, 'lawman': 1177, 'natalie': 1178, 'portman': 1179, 'troubled': 1180, 'isolated': 1181, 'greatly': 1182, 'northern': 1183, 'aggression': 1184, 'pervading': 1185, 'antiwar': 1186, 'accented': 1187, 'effective': 1188, 'haunting': 1189, 'score': 1190, 'chillingly': 1191, 'virginia': 1192, 'communicated': 1193, 'scarred': 1194, 'traumatized': 1195, 'fought': 1196, 'weapons': 1197, 'tactics': 1198, 'hellish': 1199, 'effect': 1200, 'timelessly': 1201, 'relevantbr': 1202, 'anthony': 1203, 'minghella': 1204, 'manages': 1205, 'maintain': 1206, 'gloomy': 1207, 'mood': 1208, 'denigrated': 1209, 'tepid': 1210, 'climax': 1211, 'justice': 1212, 'wonderfully': 1213, 'formed': 1214, 'awkwardly': 1215, 'tacked': 1216, 'inherently': 1217, 'distant': 1218, 'abstracted': 1219, 'fits': 1220, 'dismal': 1221, 'plotbr': 1222, 'neither': 1223, 'traits': 1224, 'feelgood': 1225, 'inspiring': 1226, 'vision': 1227, 'era': 1228, 'entertain': 1229, 'absorb': 1230, 'lives': 1231, 'apart': 1232, 'desperate': 1233, 'rid': 1234, 'repercussions': 1235, 'carpenters': 1236, 'detailsbr': 1237, 'cynthia': 1238, 'gibb': 1239, 'portrays': 1240, 'election': 1241, 'naive': 1242, 'dumb': 1243, 'personalitybr': 1244, 'louise': 1245, 'fletcher': 1246, 'agnes': 1247, 'terrific': 1248, 'karens': 1249, 'motherbr': 1250, 'songs': 1251, 'album': 1252, 'ratings': 1253, 'usa': 1254, 'countries': 1255, 'scariest': 1256, 'bird': 1257, 'dangling': 1258, 'helplessly': 1259, 'parachutes': 1260, 'horror': 1261, 'horrorbr': 1262, 'cheesy': 1263, 'saturday': 1264, 'afternoons': 1265, 'tired': 1266, 'type': 1267, 'woman': 1268, 'might': 1269, 'professor': 1270, 'resolution': 1271, 'care': 1272, 'angle': 1273, 'plots': 1274, 'unintentional': 1275, 'humorbr': 1276, 'later': 1277, 'psycho': 1278, 'loved': 1279, 'janet': 1280, 'leigh': 1281, 'bumped': 1282, 'early': 1283, 'sat': 1284, 'notice': 1285, 'screenwriters': 1286, 'scary': 1287, 'possible': 1288, 'wellworn': 1289, 'rules': 1290, 'reviewers': 1291, '1': 1292, 'youll': 1293, 'hooked': 1294, 'happened': 1295, 'mebr': 1296, 'brutality': 1297, 'unflinching': 1298, 'word': 1299, 'trust': 1300, 'faint': 1301, 'hearted': 1302, 'timid': 1303, 'pulls': 1304, 'punches': 1305, 'regards': 1306, 'hardcore': 1307, 'wordbr': 1308, 'nickname': 1309, 'oswald': 1310, 'maximum': 1311, 'security': 1312, 'state': 1313, 'penitentary': 1314, 'focuses': 1315, 'mainly': 1316, 'emerald': 1317, 'experimental': 1318, 'section': 1319, 'cells': 1320, 'glass': 1321, 'fronts': 1322, 'inwards': 1323, 'privacy': 1324, 'em': 1325, 'manyaryans': 1326, 'muslims': 1327, 'gangstas': 1328, 'latinos': 1329, 'christians': 1330, 'italians': 1331, 'moreso': 1332, 'scuffles': 1333, 'stares': 1334, 'dodgy': 1335, 'dealings': 1336, 'shady': 1337, 'agreements': 1338, 'awaybr': 1339, 'pictures': 1340, 'painted': 1341, 'mainstream': 1342, 'audiences': 1343, 'charm': 1344, 'romanceoz': 1345, 'mess': 1346, 'surreal': 1347, 'couldnt': 1348, 'developed': 1349, 'taste': 1350, 'accustomed': 1351, 'levels': 1352, 'graphic': 1353, 'injustice': 1354, 'crooked': 1355, 'guards': 1356, 'sold': 1357, 'nickel': 1358, 'order': 1359, 'mannered': 1360, 'middle': 1361, 'class': 1362, 'bitches': 1363, 'street': 1364, 'comfortable': 1365, 'uncomfortable': 1366, 'viewingthats': 1367, 'darker': 1368, 'side': 1369, 'filming': 1370, 'technique': 1371, 'unassuming': 1372, 'oldtimebbc': 1373, 'fashion': 1374, 'comforting': 1375, 'sometimes': 1376, 'discomforting': 1377, 'extremely': 1378, 'chosen': 1379, 'sheen': 1380, 'polari': 1381, 'voices': 1382, 'pat': 1383, 'seamless': 1384, 'guided': 1385, 'references': 1386, 'williams': 1387, 'diary': 1388, 'entries': 1389, 'terrificly': 1390, 'written': 1391, 'performed': 1392, 'masterful': 1393, 'masters': 1394, 'fantasy': 1395, 'guard': 1396, 'traditional': 1397, 'techniques': 1398, 'remains': 1399, 'solid': 1400, 'disappears': 1401, 'knowledge': 1402, 'senses': 1403, 'concerning': 1404, 'orton': 1405, 'halliwell': 1406, 'sets': 1407, 'flat': 1408, 'halliwells': 1409, 'murals': 1410, 'decorating': 1411, 'surface': 1412, 'terribly': 1413, 'frustrating': 1414, 'energetic': 1415, 'prepared': 1416, 'able': 1417, 'looping': 1418, 'americas': 1419, 'funniest': 1420, 'videos': 1421, 'damn': 1422, 'latino': 1423, 'speak': 1424, 'responsible': 1425, 'transcends': 1426, 'gloriously': 1427, 'badness': 1428, 'dancing': 1429, 'filmit': 1430, 'places': 1431, 'nervous': 1432, '7475': 1433, 'sister': 1434, 'berkshire': 1435, 'england': 1436, 'snow': 1437, 'appearance': 1438, 'grizzly': 1439, 'adams': 1440, 'dan': 1441, 'haggery': 1442, 'shot': 1443, 'dies': 1444, 'etc': 1445, 'please': 1446, 'knowthe': 1447, 'fitness': 1448, 'club': 1449, 'nearest': 1450, 'hear': 1451, 'misfortune': 1452, 'entiretybr': 1453, 'shouldnt': 1454, 'fmovie': 1455, 'paperthin': 1456, 'fake': 1457, 'funnyalmostbr': 1458, 'packed': 1459, 'oneliners': 1460, 'respectable': 1461, 'amusing': 1462, 'bitbr': 1463, 'geared': 1464, 'women': 1465, 'unattractive': 1466, 'wrinkled': 1467, 'appear': 1468, 'fail': 1469, 'miserablybr': 1470, 'laughs': 1471, 'petter': 1472, 'visually': 1473, 'telling': 1474, 'power': 1475, 'situations': 1476, 'encounter': 1477, 'variation': 1478, 'arthur': 1479, 'schnitzlers': 1480, 'transfers': 1481, 'present': 1482, 'york': 1483, 'meet': 1484, 'connect': 1485, 'connected': 1486, 'previous': 1487, 'contact': 1488, 'stylishly': 1489, 'sophisticated': 1490, 'luxurious': 1491, 'habitatbr': 1492, 'souls': 1493, 'stages': 1494, 'inhabits': 1495, 'fulfillment': 1496, 'discerns': 1497, 'case': 1498, 'encounterbr': 1499, 'buscemi': 1500, 'rosario': 1501, 'dawson': 1502, 'carol': 1503, 'kane': 1504, 'imperioli': 1505, 'adrian': 1506, 'grenier': 1507, 'alivebr': 1508, 'wish': 1509, 'luck': 1510, 'await': 1511, 'anxiously': 1512, 'exotic': 1513, 'masterpiece': 1514, 'dizzying': 1515, 'trip': 1516, 'vast': 1517, 'conclusive': 1518, 'evidence': 1519, 'achieved': 1520, 'beings': 1521, 'unleash': 1522, 'uninhibited': 1523, 'imaginations': 1524, 'boldness': 1525, 'pushing': 1526, 'aside': 1527, 'thoughts': 1528, 'fall': 1529, 'formulas': 1530, 'cliches': 1531, 'creating': 1532, 'magnificent': 1533, 'datebr': 1534, 'numerous': 1535, 'complaints': 1536, 'anywhere': 1537, 'substance': 1538, 'poorly': 1539, 'negatively': 1540, 'criticize': 1541, 'miss': 1542, 'landmark': 1543, 'tradition': 1544, 'future': 1545, 'hopefully': 1546, 'follow': 1547, 'opened': 1548, 'slam': 1549, 'singh': 1550, 'personally': 1551, 'welcome': 1552, 'challenge': 1553, 'himbr': 1554, 'weve': 1555, 'agree': 1556, 'overworked': 1557, 'depict': 1558, 'killers': 1559, 'worked': 1560, 'blaze': 1561, 'trail': 1562, 'twist': 1563, 'transported': 1564, 'presented': 1565, 'fascinating': 1566, 'journey': 1567, 'mysterious': 1568, 'subject': 1569, 'studiedbr': 1570, 'bog': 1571, 'scientific': 1572, 'jargon': 1573, 'explain': 1574, 'lopez': 1575, 'enter': 1576, 'lies': 1577, 'laboratory': 1578, 'table': 1579, 'wrapped': 1580, 'twizzlers': 1581, 'jaunted': 1582, 'entity': 1583, 'wants': 1584, 'explanations': 1585, 'ground': 1586, 'desires': 1587, 'showed': 1588, 'reality': 1589, 'bright': 1590, 'visuals': 1591, 'nonetheless': 1592, 'design': 1593, 'astonishing': 1594, 'surprised': 1595, 'oscars': 1596, 'itd': 1597, 'picturebr': 1598, 'repeating': 1599, 'myself': 1600, 'stress': 1601, 'open': 1602, 'wonders': 1603, 'eyepopping': 1604, 'feast': 1605, 'assured': 1606, 'crazy': 1607, 'psychology': 1608, 'alley': 1609, 'leaving': 1610, 'member': 1611, 'whoever': 1612, 'smokingbr': 1613, '4': 1614, 'book': 1615, 'splendored': 1616, 'han': 1617, 'suyin': 1618, 'tackles': 1619, 'issues': 1620, 'race': 1621, 'asians': 1622, 'whites': 1623, 'topic': 1624, 'hans': 1625, 'personal': 1626, 'experiences': 1627, 'eurasian': 1628, 'growing': 1629, 'background': 1630, 'daring': 1631, 'remembered': 1632, 'jones': 1633, 'oscar': 1634, 'doctor': 1635, 'mixed': 1636, 'breed': 1637, 'advent': 1638, 'communism': 1639, 'mainland': 1640, 'william': 1641, 'holden': 1642, 'journalist': 1643, 'covering': 1644, 'regions': 1645, 'notch': 1646, 'chemistry': 1647, 'provides': 1648, 'affection': 1649, 'melt': 1650, 'hearts': 1651, 'romantically': 1652, 'inclinedbr': 1653, 'fiftys': 1654, 'hilltop': 1655, 'overlooking': 1656, 'harbor': 1657, 'intimate': 1658, 'ending': 1659, 'tearjerker': 1660, 'consider': 1661, 'sentimental': 1662, 'romances': 1663, 'passé': 1664, 'stories': 1665, 'shining': 1666, 'example': 1667, 'taut': 1668, 'organically': 1669, 'gripping': 1670, 'dmytryks': 1671, 'distinctive': 1672, 'suspense': 1673, 'unlikely': 1674, 'devices': 1675, 'noir': 1676, 'cyclebr': 1677, 'bivouacked': 1678, 'washington': 1679, 'dc': 1680, 'company': 1681, 'restlessness': 1682, 'strangers': 1683, 'apartment': 1684, 'belligerent': 1685, 'beats': 1686, 'host': 1687, 'sam': 1688, 'levene': 1689, 'jewish': 1690, 'detective': 1691, 'investigates': 1692, 'assigned': 1693, 'outfit': 1694, 'suspicion': 1695, 'falls': 1696, 'cooper': 1697, 'vanished': 1698, 'slays': 1699, 'buddy': 1700, 'brodie': 1701, 'insure': 1702, 'silence': 1703, 'closes': 1704, 'abetted': 1705, 'superior': 1706, 'paxton': 1707, 'draws': 1708, 'precise': 1709, 'bobs': 1710, 'naturally': 1711, 'prototypical': 1712, 'angry': 1713, 'male': 1714, 'hilt': 1715, 'underplays': 1716, 'characteristic': 1717, 'alert': 1718, 'nonchalance': 1719, 'central': 1720, 'gloria': 1721, 'grahame': 1722, 'fullyfledged': 1723, 'rendition': 1724, 'smartmouthed': 1725, 'vulnerable': 1726, 'tramp': 1727, 'sad': 1728, 'sack': 1729, 'leeched': 1730, 'kelly': 1731, 'haunts': 1732, 'peripheral': 1733, 'memorablebr': 1734, 'politically': 1735, 'engaged': 1736, 'inevitably': 1737, 'succumbs': 1738, 'sermonizing': 1739, 'confined': 1740, 'youngs': 1741, 'reminiscence': 1742, 'grandfather': 1743, 'hands': 1744, 'bigots': 1745, 'thus': 1746, 'chronology': 1747, 'limit': 1748, 'render': 1749, 'explanation': 1750, 'glib': 1751, 'hates': 1752, 'jews': 1753, 'hillbillies': 1754, 'andbr': 1755, 'curiously': 1756, 'survives': 1757, 'wrought': 1758, 'novel': 1759, 'richard': 1760, 'brooks': 1761, 'brick': 1762, 'foxhole': 1763, 'gaybashing': 1764, 'homosexuality': 1765, '1947': 1766, 'pale': 1767, 'holocaust': 1768, 'begun': 1769, 'emerge': 1770, 'ashes': 1771, 'europe': 1772, 'emboldened': 1773, 'register': 1774, 'protest': 1775, 'studios': 1776, 'quaked': 1777, 'prospect': 1778, 'offending': 1779, 'potential': 1780, 'ticket': 1781, 'buyerbr': 1782, 'homophobia': 1783, 'works': 1784, 'general': 1785, 'specifics': 1786, 'smoothly': 1787, 'victims': 1788, 'chatting': 1789, 'lonesome': 1790, 'inviting': 1791, 'girlfriend': 1792, 'tow': 1793, 'raises': 1794, 'question': 1795, 'whether': 1796, 'retained': 1797, 'inadvertently': 1798, 'tipoff': 1799, 'engine': 1800, 'generating': 1801, 'murderous': 1802, 'rage': 1803, 'alltime': 1804, 'selflessness': 1805, 'sacrifice': 1806, 'dedication': 1807, 'noble': 1808, 'preachy': 1809, 'despite': 1810, 'lukas': 1811, 'tears': 1812, 'bette': 1813, 'davis': 1814, 'delight': 1815, 'grandma': 1816, 'dressedup': 1817, 'midgets': 1818, 'mothers': 1819, 'awakening': 1820, 'roof': 1821, 'startling': 1822, 'dozen': 1823, 'thumbs': 1824, 'drawn': 1825, 'erotic': 1826, 'amateurish': 1827, 'bits': 1828, 'project': 1829, 'rosanna': 1830, 'arquette': 1831, 'thinking': 1832, 'stock': 1833, 'midwest': 1834, 'involved': 1835, 'lessons': 1836, 'learned': 1837, 'insights': 1838, 'stilted': 1839, 'skin': 1840, 'intrigues': 1841, 'videotaped': 1842, 'nonsensewhat': 1843, 'bisexual': 1844, 'nowhere': 1845, 'heterosexual': 1846, 'encounters': 1847, 'dance': 1848, 'stereotyped': 1849, 'pass': 1850, 'million': 1851, 'wasted': 1852, 'spent': 1853, 'starving': 1854, 'aids': 1855, 'africa': 1856, 'resurrection': 1857, 'dated': 1858, 'tech': 1859, 'excitement': 1860, 'mei': 1861, 'grew': 1862, 'gunsmoke': 1863, 'heros': 1864, 'weekyou': 1865, 'vote': 1866, 'comeback': 1867, 'huntwe': 1868, 'water': 1869, 'adventureoh': 1870, 'thank': 1871, 'outlet': 1872, 'viewpoints': 1873, 'moviesso': 1874, 'ole': 1875, 'saywould': 1876, 'plus': 1877, 'huntif': 1878, 'rhymes': 1879, 'submitor': 1880, 'leave': 1881, 'doubt': 1882, 'quitif': 1883, 'hrs': 1884, 'regret': 1885, 'rajnikanth': 1886, 'carries': 1887, 'shoulders': 1888, 'isnt': 1889, 'anything': 1890, 'arrehman': 1891, 'grow': 1892, 'liking': 1893, 'phil': 1894, 'alien': 1895, 'quirky': 1896, 'humour': 1897, 'actual': 1898, 'punchlinesbr': 1899, 'progressed': 1900, 'anymorebr': 1901, 'low': 1902, 'budget': 1903, 'interestbr': 1904, 'imagine': 1905, 'stoner': 1906, 'currently': 1907, 'partakingbr': 1908, 'planet': 1909, 'postal': 1910, 'rights': 1911, 'ago': 1912, 'game': 1913, 'finsished': 1914, 'killing': 1915, 'mercs': 1916, 'infiltrating': 1917, 'secret': 1918, 'labs': 1919, 'located': 1920, 'tropical': 1921, 'schemed': 1922, 'legion': 1923, 'schmucks': 1924, 'loneley': 1925, 'invites': 1926, 'countrymen': 1927, 'players': 1928, 'ralf': 1929, 'moellerbr': 1930, 'selfs': 1931, 'biz': 1932, 'tale': 1933, 'jack': 1934, 'german': 1935, 'hail': 1936, 'bratwurst': 1937, 'dudes': 1938, 'tils': 1939, 'badass': 1940, 'complained': 1941, 'staying': 1942, 'perspective': 1943, 'kicking': 1944, 'demented': 1945, 'evil': 1946, 'mad': 1947, 'scientist': 1948, 'dr': 1949, 'krieger': 1950, 'geneticallymutatedsoldiers': 1951, 'performing': 1952, 'topsecret': 1953, 'spoiler': 1954, 'vancouver': 1955, 'palm': 1956, 'trees': 1957, 'rich': 1958, 'lumberjackwoods': 1959, 'gone': 1960, 'started': 1961, 'mehehe': 1962, 'stay': 1963, 'shenanigans': 1964, 'meaning': 1965, 'suckbr': 1966, 'mentioning': 1967, 'imply': 1968, 'areas': 1969, 'boat': 1970, 'cromedalbino': 1971, 'squad': 1972, 'enters': 1973, 'laugh': 1974, 'reeks': 1975, 'scheisse': 1976, 'poop': 1977, 'simpletons': 1978, 'wiff': 1979, 'ahead': 1980, 'btw': 1981, 'sidekick': 1982, 'amazing': 1983, 'fresh': 1984, 'aired': 1985, '7': 1986, '8': 1987, 'dropped': 1988, '1990': 1989, 'anymore': 1990, 'continued': 1991, 'further': 1992, 'complete': 1993, 'todaybr': 1994, 'disgraceful': 1995, 'fallen': 1996, 'painfully': 1997, 'mildly': 1998, 'respite': 1999, 'guesthosts': 2000, 'creator': 2001, 'handselected': 2002, 'chose': 2003, 'hacks': 2004, 'recognize': 2005, 'brilliance': 2006, 'replace': 2007, 'mediocrity': 2008, 'stars': 2009, 'respect': 2010, 'huge': 2011, 'gut': 2012, 'wrenching': 2013, 'laughter': 2014, 'camp': 2015, 'finest': 2016, 'indian': 2017, 'directed': 2018, 'successful': 2019, 'hitting': 2020, 'parallel': 2021, 'commercial': 2022, 'inspiration': 2023, 'directors': 2024, 'indiabr': 2025, 'reallife': 2026, 'cities': 2027, 'india': 2028, 'encompasses': 2029, 'creates': 2030, 'outlay': 2031, 'environmentbr': 2032, 'amongst': 2033, 'various': 2034, 'officers': 2035, 'colleagues': 2036, 'describes': 2037, 'hotblooded': 2038, 'harsh': 2039, 'constable': 2040, 'himself': 2041, 'suffers': 2042, 'ideologies': 2043, 'incidences': 2044, 'atrocities': 2045, 'immediate': 2046, 'inert': 2047, 'craving': 2048, 'satisfaction': 2049, 'revolved': 2050, 'wherein': 2051, 'efforts': 2052, 'trampled': 2053, 'seniorsthis': 2054, 'leads': 2055, 'achieve': 2056, 'desired': 2057, 'jobsatisfaction': 2058, 'resulting': 2059, 'anger': 2060, 'expressed': 2061, 'excessive': 2062, 'remand': 2063, 'rooms': 2064, 'alcoholicbr': 2065, 'alive': 2066, 'fights': 2067, 'aware': 2068, 'metro': 2069, 'politicians': 2070, 'inertly': 2071, 'associated': 2072, 'compromise': 2073, 'unethical': 2074, 'practice': 2075, 'negative': 2076, 'suspendedbr': 2077, 'master': 2078, 'thoroughly': 2079, 'core': 2080, 'breaks': 2081, 'underworld': 2082, 'gangster': 2083, 'rama': 2084, 'shettys': 2085, 'arrest': 2086, 'short': 2087, 'conversation': 2088, 'hairraising': 2089, 'momentsbr': 2090, 'punch': 2091, 'alcoholism': 2092, 'corruption': 2093, 'influence': 2094, 'courage': 2095, 'deceptions': 2096, 'integral': 2097, 'brilliantlybr': 2098, 'belongs': 2099, 'om': 2100, 'puri': 2101, 'portraying': 2102, 'traversing': 2103, 'emotions': 2104, 'brilliantly': 2105, 'remade': 2106, 'capture': 2107, 'flavor': 2108, '1963': 2109, 'liam': 2110, 'neeson': 2111, 'holds': 2112, 'owen': 2113, 'wilson': 2114, 'luke': 2115, 'fault': 2116, 'strayed': 2117, 'shirley': 2118, 'jackson': 2119, 'attempts': 2120, 'grandiose': 2121, 'thrill': 2122, 'trade': 2123, 'snazzier': 2124, 'special': 2125, 'effects': 2126, 'friction': 2127, 'older': 2128, 'hot': 2129, 'summer': 2130, 'weekend': 2131, 'conditioned': 2132, 'lighthearted': 2133, 'simplistic': 2134, 'witty': 2135, 'likable': 2136, 'bread': 2137, 'suspected': 2138, 'match': 2139, 'risk': 2140, 'addiction': 2141, 'proof': 2142, 'woody': 2143, 'allen': 2144, 'fully': 2145, 'control': 2146, 'grown': 2147, 'lovebr': 2148, 'laughed': 2149, 'woodys': 2150, 'comedies': 2151, 'decade': 2152, 'impressed': 2153, 'scarlet': 2154, 'johanson': 2155, 'tone': 2156, 'image': 2157, 'jumped': 2158, 'average': 2159, 'spirited': 2160, 'womanbr': 2161, 'crown': 2162, 'jewel': 2163, 'career': 2164, 'wittier': 2165, 'devil': 2166, 'wears': 2167, 'prada': 2168, 'superman': 2169, 'friends': 2170, 'encouraged': 2171, 'positive': 2172, '950': 2173, 'pacing': 2174, 'country': 2175, 'tune': 2176, 'four': 2177, 'extreme': 2178, 'rarely': 2179, 'credits': 2180, 'prevents': 2181, '1score': 2182, 'harvey': 2183, 'obsessives': 2184, 'shakespearebr': 2185, 'lostbr': 2186, 'masses': 2187, 'ruin': 2188, 'goodbr': 2189, 'certain': 2190, 'rev': 2191, 'bowdler': 2192, 'hence': 2193, 'bowdlerization': 2194, 'victorian': 2195, 'erabr': 2196, 'words': 2197, 'improve': 2198, 'perfectionbr': 2199, 'text': 2200, 'composition': 2201, 'forte': 2202, 'saying': 2203, 'cut': 2204, 'exposure': 2205, 'templarios': 2206, 'excited': 2207, 'among': 2208, 'offerings': 2209, 'anchor': 2210, 'bay': 2211, 'cult': 2212, 'classics': 2213, 'baby': 2214, 'print': 2215, 'quality': 2216, 'alone': 2217, 'hide': 2218, 'deadly': 2219, 'dull': 2220, 'thrilling': 2221, 'opening': 2222, 'villagers': 2223, 'exact': 2224, 'revenge': 2225, 'templars': 2226, 'motion': 2227, 'ponderous': 2228, 'unfulfilling': 2229, 'adding': 2230, 'insult': 2231, 'injury': 2232, 'dubbed': 2233, 'subtitled': 2234, 'promised': 2235, 'jacket': 2236, 'withbr': 2237, 'achingly': 2238, 'heroine': 2239, 'menace': 2240, 'foreboding': 2241, 'thunderstorms': 2242, 'strangely': 2243, 'housegreat': 2244, 'double': 2245, 'glazing': 2246, 'serves': 2247, 'purpose': 2248, 'quick': 2249, 'gory': 2250, 'tedium': 2251, 'unbearable': 2252, 'suggests': 2253, 'spate': 2254, 'throughout': 2255, 'area': 2256, 'apparent': 2257, 'ritual': 2258, 'salt': 2259, 'pepper': 2260, 'sums': 2261, 'inherent': 2262, 'directionbr': 2263, 'add': 2264, 'act': 2265, 'willing': 2266, 'completely': 2267, 'nude': 2268, 'shower': 2269, 'hopebr': 2270, 'following': 2271, 'banned': 2272, 'uk': 2273, '80s': 2274, 'extended': 2275, 'curiosity': 2276, 'value': 2277, 'daft': 2278, 'worryits': 2279, 'telegraphed': 2280, 'beforebr': 2281, 'woods': 2282, 'steep': 2283, 'upward': 2284, 'slope': 2285, 'obviously': 2286, 'figure': 2287, 'dressed': 2288, 'brandishing': 2289, 'large': 2290, 'scythe': 2291, 'slide': 2292, 'conveniently': 2293, 'upright': 2294, 'front': 2295, 'weaponbr': 2296, '300': 2297, 'sounded': 2298, 'ranmaesque': 2299, 'dragging': 2300, 'skeleton': 2301, 'cute': 2302, 'viewing': 2303, 'sweet': 2304, 'indie': 2305, 'edge': 2306, '100': 2307, 'wrongbr': 2308, 'wonder': 2309, 'hardly': 2310, 'foul': 2311, 'language': 2312, 'closest': 2313, 'nudity': 2314, 'hoping': 2315, 'nightgown': 2316, 'antireligious': 2317, 'humor': 2318, 'tame': 2319, 'caricatured': 2320, 'insincere': 2321, 'derivative': 2322, 'unoriginal': 2323, 'slightestit': 2324, 'listen': 2325, 'stevens': 2326, 'jesus': 2327, 'wear': 2328, 'rolex': 2329, 'television': 2330, 'qualify': 2331, 'refuses': 2332, '17': 2333, 'thisas': 2334, 'pornographic': 2335, 'requiem': 2336, 'insist': 2337, 'zack': 2338, 'reba': 2339, 'worsebr': 2340, 'waybr': 2341, 'worries': 2342, 'methe': 2343, 'offend': 2344, 'needs': 2345, 'portrayed': 2346, 'ones': 2347, 'virgin': 2348, 'r': 2349, 'purely': 2350, 'aspect': 2351, 'eleven': 2352, 'twelve': 2353, 'causes': 2354, 'number': 2355, 'chances': 2356, 'teens': 2357, '210': 2358, 'investigate': 2359, 'dunnit': 2360, 'including': 2361, 'okay': 2362, 'route': 2363, 'morses': 2364, 'ride': 2365, 'pickle': 2366, 'morse': 2367, 'greatest': 2368, 'coolest': 2369, 'koepp': 2370, 'writer': 2371, 'heavenbr': 2372, 'rubbish': 2373, 'baffles': 2374, 'hope': 2375, 'significant': 2376, 'quotes': 2377, 'pronounced': 2378, 'protagonist': 2379, 'mafia': 2380, 'middleman': 2381, 'nondescript': 2382, 'middleaged': 2383, 'salerno': 2384, 'living': 2385, 'elegant': 2386, 'sterile': 2387, 'italianspeaking': 2388, 'canton': 2389, 'switzerland': 2390, 'conducting': 2391, 'business': 2392, 'gradually': 2393, 'pivotal': 2394, 'unremarkable': 2395, 'employees': 2396, 'swiss': 2397, 'normally': 2398, 'count': 2399, 'cash': 2400, '10000': 2401, 'dollars': 2402, 'missing': 2403, 'suitcase': 2404, 'tightly': 2405, 'stacked': 2406, 'banknotes': 2407, 'quietly': 2408, 'icily': 2409, 'threatens': 2410, 'coaxing': 2411, 'manager': 2412, 'close': 2413, 'account': 2414, 'fear': 2415, 'bluffed': 2416, 'told': 2417, 'accepted': 2418, 'initially': 2419, 'scowling': 2420, 'taciturn': 2421, 'curt': 2422, 'verge': 2423, '50': 2424, 'reply': 2425, 'chambermaids': 2426, 'waitresses': 2427, 'hello': 2428, 'goodbye': 2429, 'described': 2430, 'days': 2431, 'nights': 2432, 'oddly': 2433, 'disjoined': 2434, 'deliberate': 2435, 'revealing': 2436, 'seemingly': 2437, 'mundane': 2438, 'details': 2439, 'unnecessary': 2440, 'essential': 2441, 'masterfully': 2442, 'constructed': 2443, 'identity': 2444, 'loving': 2445, 'conveyed': 2446, 'elegantly': 2447, 'boards': 2448, 'canada': 2449, 'stood': 2450, 'treat': 2451, 'mobsters': 2452, 'odds': 2453, 'release': 2454, 'element': 2455, 'protagonists': 2456, 'machinist': 2457, 'explicit': 2458, 'al': 2459, 'pacino': 2460, 'uses': 2461, 'condition': 2462, 'symbolise': 2463, 'deeper': 2464, 'malaise': 2465, 'rammed': 2466, 'deep': 2467, 'obscurity': 2468, 'unconscious': 2469, 'impossible': 2470, 'pinpoint': 2471, 'waitress': 2472, 'sofia': 2473, 'olivia': 2474, 'magnani': 2475, 'granddaughter': 2476, 'legendary': 2477, 'anna': 2478, 'memory': 2479, 'tittas': 2480, 'friend': 2481, 'hasnt': 2482, 'tiny': 2483, 'window': 2484, 'tentatively': 2485, 'accepts': 2486, 'explicitly': 2487, 'spelt': 2488, 'accepting': 2489, 'unimaginable': 2490, 'single': 2491, 'concedes': 2492, 'representative': 2493, 'quiet': 2494, 'taking': 2495, 'italian': 2496, 'cinecittà': 2497, 'waiting': 2498, 'produce': 2499, 'il': 2500, 'postinolike': 2501, 'fare': 2502, 'la': 2503, 'vita': 2504, 'è': 2505, 'bellastyle': 2506, 'neglecting': 2507, 'explore': 2508, 'creations': 2509, 'loss': 2510, 'continuous': 2511, 'minute': 2512, 'busy': 2513, 'running': 2514, 'sword': 2515, 'attachment': 2516, 'wanted': 2517, 'destroy': 2518, 'blatantly': 2519, 'lotr': 2520, 'matrix': 2521, 'examplesbr': 2522, 'ghost': 2523, 'yoda': 2524, 'obee': 2525, 'vader': 2526, 'frodo': 2527, 'attacked': 2528, 'return': 2529, 'elijah': 2530, 'wood': 2531, 'waitit': 2532, 'hypnotizes': 2533, 'stings': 2534, 'wraps': 2535, 'upuh': 2536, 'hellobr': 2537, 'vs': 2538, 'humans': 2539, 'matrixor': 2540, 'terminatorbr': 2541, 'examples': 2542, 'line': 2543, 'rushed': 2544, 'conclusion': 2545, 'childrens': 2546, 'adult': 2547, 'either': 2548, 'disappointment': 2549}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "we will start creating dictionary with index 1 because 0 is reserved for padding\n",
    "'''\n",
    "\n",
    "vocab_to_int={w:i+1 for i,(w,c) in enumerate(sorted_words)}\n",
    "print(vocab_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Uz3jgermSMXW"
   },
   "outputs": [],
   "source": [
    "encoded_reviews=list()\n",
    "for review in all_reviews:\n",
    "  encoded_review=list()\n",
    "  for word in review.split():\n",
    "    if word not in vocab_to_int.keys():\n",
    "      #if word is not available in vocab_to_int put 0 in that place\n",
    "      encoded_review.append(0)\n",
    "    else:\n",
    "      encoded_review.append(vocab_to_int[word])\n",
    "  encoded_reviews.append(encoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "InxnEGFDSQG8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "'''\n",
    "this step will Return features of review_ints, where each review is padded with 0's or truncated to the input seq_length.\n",
    "'''\n",
    "sequence_length=250\n",
    "features=np.zeros((len(encoded_reviews), sequence_length), dtype=int)\n",
    "for i, review in enumerate(encoded_reviews):\n",
    "  review_len=len(review)\n",
    "  if (review_len<=sequence_length):\n",
    "    zeros=list(np.zeros(sequence_length-review_len))\n",
    "    new=zeros+review\n",
    "  else:\n",
    "    new=review[:sequence_length]\n",
    "      \n",
    "  features[i,:]=np.array(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l0lm28xjSY3C"
   },
   "outputs": [],
   "source": [
    "#Our dataset has ‘positive’ and ‘negative’ as a label, it will be easy if we have 1 and 0, instead of ‘positive’ and ‘negative’\n",
    "labels=[1 if label.strip()=='positive' else 0 for label in imdb_dataset.sentiment.to_list()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63xHJ7aco8__"
   },
   "source": [
    "### Train, validation, and test set splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoOnFglvSY6H",
    "outputId": "dbf6c782-8db2-43eb-d5ef-d94ae9cd9a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 8 8\n"
     ]
    }
   ],
   "source": [
    "#split_dataset into 80% training , 10% test and 10% Validation Dataset\n",
    "train_x=features[:int(0.6*len(features))]\n",
    "train_y=labels[:int(0.6*len(features))]\n",
    "valid_x=features[int(0.6*len(features)):int(0.8*len(features))]\n",
    "valid_y=labels[int(0.6*len(features)):int(0.8*len(features))]\n",
    "test_x=features[int(0.8*len(features)):]\n",
    "test_y=labels[int(0.8*len(features)):]\n",
    "print(len(train_y), len(valid_y), len(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qh0PVeWAS4H3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#create Tensor Dataset\n",
    "train_data=TensorDataset(torch.LongTensor(train_x), torch.FloatTensor(train_y)) #Changed to LongTensor\n",
    "valid_data=TensorDataset(torch.LongTensor(valid_x), torch.FloatTensor(valid_y)) #Changed to LongTensor\n",
    "test_data=TensorDataset(torch.LongTensor(test_x), torch.FloatTensor(test_y)) #Changed to LongTensor\n",
    "\n",
    "#dataloader\n",
    "batch_size=24\n",
    "train_loader=DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "valid_loader=DataLoader(valid_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader=DataLoader(test_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVO0MbbapF2Y"
   },
   "source": [
    "### LSTM model specification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "E1HsdxfITs5I"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Basic implementation of an LSTM for binary sentiment classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the model by setting up the layers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.output_size=output_size\n",
    "        self.n_layers=n_layers\n",
    "        self.hidden_dim=hidden_dim\n",
    "\n",
    "        #Embedding and LSTM layers\n",
    "        self.embedding=nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm=nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "        #dropout layer\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "\n",
    "        #Linear and sigmoid layer\n",
    "        self.fc1=nn.Linear(hidden_dim, 64)\n",
    "        self.fc2=nn.Linear(64, 16)\n",
    "        self.fc3=nn.Linear(16,output_size)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size=x.size()\n",
    "\n",
    "        #Embadding and LSTM output\n",
    "        embedd=self.embedding(x)\n",
    "        lstm_out, hidden=self.lstm(embedd, hidden)\n",
    "\n",
    "        #stack up the lstm output\n",
    "        lstm_out=lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        #dropout and fully connected layers\n",
    "        out=self.dropout(lstm_out)\n",
    "        out=self.fc1(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc2(out)\n",
    "        out=self.dropout(out)\n",
    "        out=self.fc3(out)\n",
    "        sig_out=self.sigmoid(out)\n",
    "\n",
    "        sig_out=sig_out.view(batch_size, -1)\n",
    "        sig_out=sig_out[:, -1]\n",
    "\n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize Hidden STATE\"\"\"\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "\n",
    "        if (train_on_gpu):\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
    "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
    "        else:\n",
    "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peGTlJnApMR5"
   },
   "source": [
    "### Instantiate the model with hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kY3SwqXyT1Sj",
    "outputId": "f307fbc8-75d4-407e-892f-8e72a838ae17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentimentLSTM(\n",
      "  (embedding): Embedding(2550, 400)\n",
      "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  (fc3): Linear(in_features=16, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
    "output_size = 1\n",
    "embedding_dim = 400\n",
    "hidden_dim = 256\n",
    "n_layers = 2\n",
    "drop_prob = 0.5\n",
    "\n",
    "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmOM-7OroEKV"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-oraRKNZ0Ze",
    "outputId": "be7a6680-7ba1-4f09-9f9d-5d04dea0d6dd"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# train for some number of epochs\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# initialize hidden state\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "lr = 0.01\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "# check if CUDA is available\n",
    "train_on_gpu = False#torch.cuda.is_available()\n",
    "\n",
    "# training params\n",
    "epochs = \n",
    "\n",
    "counter = 0\n",
    "print_every = 10\n",
    "clip = 5 # gradient clipping\n",
    "\n",
    "# move model to GPU, if available\n",
    "if(train_on_gpu):\n",
    "    net.cuda()\n",
    "\n",
    "net.train()\n",
    "# train for some number of epochs\n",
    "for e in range(epochs):\n",
    "    print(f\"epoch {e}\")\n",
    "    # initialize hidden state\n",
    "    h = net.init_hidden(batch_size)\n",
    "\n",
    "    # batch loop\n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        if(train_on_gpu):\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # Creating new variables for the hidden state, otherwise\n",
    "        # we'd backprop through the entire training history\n",
    "        h = tuple([each.data for each in h])\n",
    "\n",
    "        # zero out accumulated gradients\n",
    "        #net.zero_grad()\n",
    "        #get the output from the model\n",
    "        output, h = net(inputs, h)\n",
    "\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output.squeeze(), labels.float()) # Changed labels.long() to labels.float()\n",
    "        loss.backward()\n",
    "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
    "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        # loss stats\n",
    "        if counter % print_every == 0:\n",
    "            # Get validation loss\n",
    "            val_h = net.init_hidden(batch_size)\n",
    "            val_losses = []\n",
    "            net.eval()\n",
    "            for inputs, labels in valid_loader:\n",
    "\n",
    "                # Creating new variables for the hidden state, otherwise\n",
    "                # we'd backprop through the entire training history\n",
    "                val_h = tuple([each.data for each in val_h])\n",
    "\n",
    "                #inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                output, val_h = net(inputs, val_h)\n",
    "                val_loss = criterion(output.squeeze(), labels.float())\n",
    "\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            net.train()\n",
    "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epXKuwi2oMK8"
   },
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9FfPCroVbaJC",
    "outputId": "d10ac843-d5e5-47f9-e631-22eee259c1fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 19.024\n",
      "Test accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "h = net.init_hidden(8)\n",
    "blah = True\n",
    "net.eval()\n",
    "# iterate over test data\n",
    "for inputs, labels in test_loader:\n",
    "  # Creating new variables for the hidden state, otherwise\n",
    "  # we'd backprop through the entire training history\n",
    "  h = tuple([each.data for each in h])\n",
    "\n",
    "  #inputs, labels = inputs.cuda(), labels.cuda()\n",
    "  output, h = net(inputs, h)\n",
    "  # calculate loss\n",
    "  test_loss = criterion(output.squeeze(), labels.float())\n",
    "  test_losses.append(test_loss.item())\n",
    "\n",
    "  # convert output probabilities to predicted class (0 or 1)\n",
    "  pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "  # compare predictions to true label\n",
    "  correct_tensor = pred.eq(labels.float().view_as(pred))\n",
    "  correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
    "  num_correct += np.sum(correct)\n",
    "\n",
    "  # avg test loss\n",
    "  print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "  # accuracy over all test data\n",
    "  test_acc = num_correct/len(test_loader.dataset)\n",
    "  print(\"Test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
